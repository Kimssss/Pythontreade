#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì‹œìŠ¤í…œ
ì‹¤ì‹œê°„ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ê°ì„± ë¶„ì„
"""

import logging
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json
from pathlib import Path
import pandas as pd
import numpy as np
import re
import time
from bs4 import BeautifulSoup

# ê°ì„± ë¶„ì„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

logger = logging.getLogger('ai_trading.sentiment')


class KoreanSentimentAnalyzer:
    """í•œêµ­ì–´ ê°ì„± ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.positive_words = [
            'ìƒìŠ¹', 'ê¸‰ë“±', 'ê°•ì„¸', 'í˜¸ì¬', 'ê¸ì •', 'ì„±ì¥', 'ìˆ˜ìµ', 'ì´ìµ', 
            'ì¦ê°€', 'ê°œì„ ', 'í˜¸ì¡°', 'ëŒíŒŒ', 'ì‹ ê³ ê°€', 'ë°˜ë“±', 'íšŒë³µ'
        ]
        self.negative_words = [
            'í•˜ë½', 'ê¸‰ë½', 'ì•½ì„¸', 'ì•…ì¬', 'ë¶€ì •', 'ê°ì†Œ', 'ì†ì‹¤', 'ìš°ë ¤',
            'í•˜ë½ì„¸', 'ì¹¨ì²´', 'ì•…í™”', 'ë¶€ì§„', 'ì‹ ì €ê°€', 'í­ë½', 'ìœ„í—˜'
        ]
        
        if TRANSFORMERS_AVAILABLE:
            self._load_model()
        
        logger.info("Korean Sentiment Analyzer initialized")
    
    def _load_model(self):
        """í•œêµ­ì–´ ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ"""
        try:
            model_name = "klue/roberta-base"
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            logger.info("Korean sentiment model loaded successfully")
        except Exception as e:
            logger.warning(f"Pre-trained model load failed, using rule-based: {e}")
    
    def analyze(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„"""
        if not text or not text.strip():
            return {'sentiment': 'neutral', 'confidence': 0.0, 'score': 0.0}
        
        # ì „ì²˜ë¦¬
        cleaned_text = self._preprocess_text(text)
        
        if TRANSFORMERS_AVAILABLE and self.tokenizer:
            return self._analyze_with_model(cleaned_text)
        else:
            return self._analyze_with_rules(cleaned_text)
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def _analyze_with_model(self, text: str) -> Dict:
        """ëª¨ë¸ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        try:
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ëª¨ë¸ ì‚¬ìš©
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´
            return self._analyze_with_rules(text)
        except Exception as e:
            logger.error(f"Model analysis failed: {e}")
            return self._analyze_with_rules(text)
    
    def _analyze_with_rules(self, text: str) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        positive_score = 0
        negative_score = 0
        
        # ê¸ì • ë‹¨ì–´ ì¹´ìš´íŠ¸
        for word in self.positive_words:
            positive_score += text.count(word) * 1.0
        
        # ë¶€ì • ë‹¨ì–´ ì¹´ìš´íŠ¸  
        for word in self.negative_words:
            negative_score += text.count(word) * 1.0
        
        total_score = positive_score + negative_score
        
        if total_score == 0:
            return {'sentiment': 'neutral', 'confidence': 0.0, 'score': 0.0}
        
        # ê°ì„± ì ìˆ˜ ê³„ì‚° (-1 ~ 1)
        score = (positive_score - negative_score) / (positive_score + negative_score + 1e-6)
        confidence = min(total_score / 10.0, 1.0)  # ìµœëŒ€ 1.0
        
        # ê°ì„± ë¼ë²¨ ê²°ì •
        if score > 0.2:
            sentiment = 'positive'
        elif score < -0.2:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'score': score,
            'positive_score': positive_score,
            'negative_score': negative_score
        }


class NewsCollector:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.news_sources = {
            'naver_finance': 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258',
            'hankyung': 'https://www.hankyung.com/finance',
            'mk': 'https://www.mk.co.kr/news/economy/'
        }
        self.session = None
        
        logger.info("News Collector initialized")
    
    async def collect_news(self, stock_code: str = None, hours: int = 24) -> List[Dict]:
        """ë‰´ìŠ¤ ìˆ˜ì§‘"""
        all_news = []
        
        async with aiohttp.ClientSession() as session:
            self.session = session
            
            try:
                # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤
                naver_news = await self._collect_naver_finance_news(stock_code)
                all_news.extend(naver_news)
                
                await asyncio.sleep(1)  # ìš”ì²­ ê°„ê²©
                
                # í•œêµ­ê²½ì œ ë‰´ìŠ¤
                hankyung_news = await self._collect_hankyung_news()
                all_news.extend(hankyung_news)
                
                await asyncio.sleep(1)
                
                # ë§¤ì¼ê²½ì œ ë‰´ìŠ¤
                mk_news = await self._collect_mk_news()
                all_news.extend(mk_news)
                
            except Exception as e:
                logger.error(f"News collection failed: {e}")
        
        # ì‹œê°„ í•„í„°ë§
        cutoff_time = datetime.now() - timedelta(hours=hours)
        filtered_news = [
            news for news in all_news 
            if news.get('published_at', datetime.now()) > cutoff_time
        ]
        
        logger.info(f"Collected {len(filtered_news)} news articles")
        return filtered_news
    
    async def _collect_naver_finance_news(self, stock_code: str = None) -> List[Dict]:
        """ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_list = []
        
        try:
            url = self.news_sources['naver_finance']
            if stock_code:
                url += f"&code={stock_code}"
            
            async with self.session.get(url, timeout=10) as response:
                if response.status != 200:
                    return news_list
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹±
                items = soup.find_all('tr', class_='')[:10]  # ìƒìœ„ 10ê°œ
                
                for item in items:
                    try:
                        title_elem = item.find('a')
                        if not title_elem:
                            continue
                        
                        title = title_elem.get_text(strip=True)
                        link = title_elem.get('href', '')
                        
                        if link.startswith('/'):
                            link = f"https://finance.naver.com{link}"
                        
                        news_list.append({
                            'title': title,
                            'content': title,  # ê°„ë‹¨íˆ ì œëª©ì„ ë‚´ìš©ìœ¼ë¡œ ì‚¬ìš©
                            'link': link,
                            'source': 'naver_finance',
                            'published_at': datetime.now(),
                            'stock_code': stock_code
                        })
                        
                    except Exception as e:
                        logger.debug(f"Naver news item parsing error: {e}")
                        continue
                        
        except Exception as e:
            logger.error(f"Naver finance news collection failed: {e}")
        
        return news_list
    
    async def _collect_hankyung_news(self) -> List[Dict]:
        """í•œêµ­ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_list = []
        
        try:
            url = self.news_sources['hankyung']
            
            async with self.session.get(url, timeout=10) as response:
                if response.status != 200:
                    return news_list
                
                # ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„° (ì‹¤ì œë¡œëŠ” HTML íŒŒì‹± í•„ìš”)
                news_list = [
                    {
                        'title': f'í•œê²½ ê²½ì œë‰´ìŠ¤ {i+1}',
                        'content': f'í•œêµ­ê²½ì œ ë‰´ìŠ¤ ë‚´ìš© {i+1}',
                        'link': f'https://www.hankyung.com/news/{i+1}',
                        'source': 'hankyung',
                        'published_at': datetime.now() - timedelta(hours=i),
                        'stock_code': None
                    }
                    for i in range(5)
                ]
                
        except Exception as e:
            logger.error(f"Hankyung news collection failed: {e}")
        
        return news_list
    
    async def _collect_mk_news(self) -> List[Dict]:
        """ë§¤ì¼ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        news_list = []
        
        try:
            url = self.news_sources['mk']
            
            async with self.session.get(url, timeout=10) as response:
                if response.status != 200:
                    return news_list
                
                # ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„°
                news_list = [
                    {
                        'title': f'ë§¤ê²½ ì¦ì‹œë‰´ìŠ¤ {i+1}',
                        'content': f'ë§¤ì¼ê²½ì œ ì¦ì‹œ ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš© {i+1}',
                        'link': f'https://www.mk.co.kr/news/{i+1}',
                        'source': 'mk',
                        'published_at': datetime.now() - timedelta(hours=i*2),
                        'stock_code': None
                    }
                    for i in range(3)
                ]
                
        except Exception as e:
            logger.error(f"MK news collection failed: {e}")
        
        return news_list


class SentimentSignalGenerator:
    """ê°ì„± ê¸°ë°˜ ë§¤ë§¤ ì‹ í˜¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.analyzer = KoreanSentimentAnalyzer()
        self.collector = NewsCollector()
        
        # ê°ì„± ì ìˆ˜ ì„ê³„ê°’
        self.bullish_threshold = 0.3
        self.bearish_threshold = -0.3
        
        logger.info("Sentiment Signal Generator initialized")
    
    async def generate_market_sentiment_signal(self) -> Dict:
        """ì‹œì¥ ì „ì²´ ê°ì„± ì‹ í˜¸ ìƒì„±"""
        try:
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            news_articles = await self.collector.collect_news(hours=12)
            
            if not news_articles:
                return self._default_sentiment_signal()
            
            # ê°ì„± ë¶„ì„
            sentiment_scores = []
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            
            for article in news_articles:
                result = self.analyzer.analyze(article['content'])
                sentiment_scores.append(result['score'])
                
                if result['sentiment'] == 'positive':
                    positive_count += 1
                elif result['sentiment'] == 'negative':
                    negative_count += 1
                else:
                    neutral_count += 1
            
            # ì „ì²´ ê°ì„± ì ìˆ˜ ê³„ì‚°
            avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
            sentiment_std = np.std(sentiment_scores) if len(sentiment_scores) > 1 else 0.0
            
            # ì‹ í˜¸ ìƒì„±
            signal_strength = 0.0
            signal_direction = 'neutral'
            
            if avg_sentiment > self.bullish_threshold:
                signal_direction = 'bullish'
                signal_strength = min(avg_sentiment, 1.0)
            elif avg_sentiment < self.bearish_threshold:
                signal_direction = 'bearish'
                signal_strength = min(abs(avg_sentiment), 1.0)
            
            return {
                'signal_direction': signal_direction,
                'signal_strength': signal_strength,
                'average_sentiment': avg_sentiment,
                'sentiment_volatility': sentiment_std,
                'article_count': len(news_articles),
                'sentiment_distribution': {
                    'positive': positive_count,
                    'negative': negative_count,
                    'neutral': neutral_count
                },
                'confidence': min(len(news_articles) / 20.0, 1.0),  # ë‰´ìŠ¤ ê°œìˆ˜ì— ë¹„ë¡€
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Sentiment signal generation failed: {e}")
            return self._default_sentiment_signal()
    
    async def generate_stock_sentiment_signal(self, stock_code: str) -> Dict:
        """ê°œë³„ ì¢…ëª© ê°ì„± ì‹ í˜¸ ìƒì„±"""
        try:
            # ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
            news_articles = await self.collector.collect_news(stock_code=stock_code, hours=24)
            
            if not news_articles:
                return self._default_sentiment_signal()
            
            # ê°ì„± ë¶„ì„
            sentiment_scores = []
            for article in news_articles:
                result = self.analyzer.analyze(article['content'])
                sentiment_scores.append(result['score'])
            
            avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
            
            # ì‹ í˜¸ ê°•ë„ ê³„ì‚° (ì¢…ëª©ë³„ì€ ë” ë³´ìˆ˜ì )
            signal_strength = 0.0
            signal_direction = 'neutral'
            
            if avg_sentiment > self.bullish_threshold * 1.5:  # ë” ë†’ì€ ì„ê³„ê°’
                signal_direction = 'bullish'
                signal_strength = min(avg_sentiment * 0.8, 1.0)  # ì‹ í˜¸ ê°•ë„ ê°ì†Œ
            elif avg_sentiment < self.bearish_threshold * 1.5:
                signal_direction = 'bearish'
                signal_strength = min(abs(avg_sentiment) * 0.8, 1.0)
            
            return {
                'stock_code': stock_code,
                'signal_direction': signal_direction,
                'signal_strength': signal_strength,
                'average_sentiment': avg_sentiment,
                'article_count': len(news_articles),
                'confidence': min(len(news_articles) / 10.0, 1.0),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Stock sentiment signal generation failed: {e}")
            return self._default_sentiment_signal()
    
    def _default_sentiment_signal(self) -> Dict:
        """ê¸°ë³¸ ì¤‘ë¦½ ì‹ í˜¸"""
        return {
            'signal_direction': 'neutral',
            'signal_strength': 0.0,
            'average_sentiment': 0.0,
            'sentiment_volatility': 0.0,
            'article_count': 0,
            'confidence': 0.0,
            'timestamp': datetime.now().isoformat()
        }


class SentimentAgent:
    """ê°ì„± ë¶„ì„ ì—ì´ì „íŠ¸ (ì•™ìƒë¸” ì‹œìŠ¤í…œìš©)"""
    
    def __init__(self):
        self.signal_generator = SentimentSignalGenerator()
        self.last_update = None
        self.market_sentiment_cache = None
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
        
        logger.info("Sentiment Agent initialized")
    
    async def get_trading_signal(self, stock_code: str, current_price: float) -> Dict:
        """ê±°ë˜ ì‹ í˜¸ ìƒì„±"""
        try:
            # ì‹œì¥ ê°ì„±ê³¼ ê°œë³„ ì¢…ëª© ê°ì„± ê²°í•©
            market_signal = await self._get_market_sentiment()
            stock_signal = await self.signal_generator.generate_stock_sentiment_signal(stock_code)
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì‹ í˜¸ ê³„ì‚°
            market_weight = 0.6
            stock_weight = 0.4
            
            market_score = self._signal_to_score(market_signal)
            stock_score = self._signal_to_score(stock_signal)
            
            final_score = market_score * market_weight + stock_score * stock_weight
            
            # ìµœì¢… ì‹ í˜¸ ê²°ì •
            if final_score > 0.3:
                action = 'buy'
                confidence = min(final_score, 1.0)
            elif final_score < -0.3:
                action = 'sell'
                confidence = min(abs(final_score), 1.0)
            else:
                action = 'hold'
                confidence = 1.0 - abs(final_score)
            
            return {
                'action': action,
                'confidence': confidence,
                'sentiment_score': final_score,
                'market_sentiment': market_signal,
                'stock_sentiment': stock_signal,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Sentiment trading signal failed: {e}")
            return {
                'action': 'hold',
                'confidence': 0.0,
                'sentiment_score': 0.0,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def _get_market_sentiment(self) -> Dict:
        """ìºì‹œëœ ì‹œì¥ ê°ì„± ì¡°íšŒ"""
        now = datetime.now()
        
        if (self.market_sentiment_cache is None or 
            self.last_update is None or 
            (now - self.last_update).total_seconds() > self.cache_ttl):
            
            self.market_sentiment_cache = await self.signal_generator.generate_market_sentiment_signal()
            self.last_update = now
        
        return self.market_sentiment_cache
    
    def _signal_to_score(self, signal: Dict) -> float:
        """ì‹ í˜¸ë¥¼ ìˆ˜ì¹˜ ì ìˆ˜ë¡œ ë³€í™˜"""
        direction = signal.get('signal_direction', 'neutral')
        strength = signal.get('signal_strength', 0.0)
        confidence = signal.get('confidence', 0.0)
        
        if direction == 'bullish':
            return strength * confidence
        elif direction == 'bearish':
            return -strength * confidence
        else:
            return 0.0


# ê°ì„± ë¶„ì„ ëª¨ë‹ˆí„°ë§ ë° ë°ì´í„° ì €ì¥
async def save_sentiment_data(sentiment_data: Dict, file_path: str = "sentiment_analysis_202512.json"):
    """ê°ì„± ë¶„ì„ ë°ì´í„° ì €ì¥"""
    try:
        sentiment_file = Path(file_path)
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = []
        if sentiment_file.exists():
            with open(sentiment_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        existing_data.append(sentiment_data)
        
        # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
        if len(existing_data) > 1000:
            existing_data = existing_data[-1000:]
        
        # ì €ì¥
        with open(sentiment_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Sentiment data saved: {len(existing_data)} records")
        
    except Exception as e:
        logger.error(f"Sentiment data save failed: {e}")


if __name__ == "__main__":
    async def test_sentiment_system():
        """ê°ì„± ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        print("ğŸ” ê°ì„± ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ê°ì„± ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
        analyzer = KoreanSentimentAnalyzer()
        
        test_texts = [
            "ì‚¼ì„±ì „ì ì£¼ê°€ ê¸‰ë“±! ì‹ ê³ ê°€ ëŒíŒŒ ì „ë§",
            "ì¦ì‹œ í­ë½, íˆ¬ììë“¤ ìš°ë ¤ í™•ì‚°",
            "ì˜¤ëŠ˜ ì½”ìŠ¤í”¼ëŠ” ë³´í•©ì„¸ë¥¼ ìœ ì§€í–ˆë‹¤",
            "AI ê´€ë ¨ì£¼ ê°•ì„¸, ì„±ì¥ ì „ë§ ë°ì•„"
        ]
        
        print("\nğŸ“Š í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ ê²°ê³¼:")
        for text in test_texts:
            result = analyzer.analyze(text)
            print(f"í…ìŠ¤íŠ¸: {text}")
            print(f"ê°ì„±: {result['sentiment']}, ì ìˆ˜: {result['score']:.3f}, ì‹ ë¢°ë„: {result['confidence']:.3f}\n")
        
        # ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        collector = NewsCollector()
        news = await collector.collect_news(hours=24)
        print(f"ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news)}ê°œ")
        
        # ê°ì„± ì‹ í˜¸ ìƒì„± í…ŒìŠ¤íŠ¸
        signal_gen = SentimentSignalGenerator()
        market_signal = await signal_gen.generate_market_sentiment_signal()
        print(f"\nğŸ“ˆ ì‹œì¥ ê°ì„± ì‹ í˜¸:")
        print(f"ë°©í–¥: {market_signal['signal_direction']}")
        print(f"ê°•ë„: {market_signal['signal_strength']:.3f}")
        print(f"í‰ê·  ê°ì„±: {market_signal['average_sentiment']:.3f}")
        
        # ê°ì„± ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
        agent = SentimentAgent()
        trading_signal = await agent.get_trading_signal("005930", 75000)  # ì‚¼ì„±ì „ì
        print(f"\nğŸ¤– ê±°ë˜ ì‹ í˜¸:")
        print(f"í–‰ë™: {trading_signal['action']}")
        print(f"ì‹ ë¢°ë„: {trading_signal['confidence']:.3f}")
        print(f"ê°ì„± ì ìˆ˜: {trading_signal['sentiment_score']:.3f}")
        
        # ë°ì´í„° ì €ì¥
        await save_sentiment_data(market_signal)
        print("\nğŸ’¾ ê°ì„± ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_sentiment_system())