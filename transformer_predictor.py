#!/usr/bin/env python3
"""
Transformer ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸
- ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ í™œìš©
- ë‹¤ì¤‘ ì‹œê°„ëŒ€ ë¶„ì„
- ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
"""

import numpy as np
import pandas as pd
from typing import List, Tuple, Optional, Dict
import logging
from datetime import datetime, timedelta

try:
    import tensorflow as tf
    from tensorflow.keras.layers import (
        Input, Dense, LayerNormalization, MultiHeadAttention,
        Dropout, GlobalAveragePooling1D, Reshape
    )
    from tensorflow.keras.models import Model
    from tensorflow.keras.optimizers import Adam
    HAS_TF = True
except ImportError:
    HAS_TF = False
    print("âš ï¸ TensorFlowë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TransformerBlock(tf.keras.layers.Layer):
    """
Transformer ë¸”ë¡
    """
    
    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):
        super(TransformerBlock, self).__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        
        if HAS_TF:
            self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
            self.ffn = tf.keras.Sequential([
                Dense(ff_dim, activation="relu"),
                Dense(embed_dim),
            ])
            self.layernorm1 = LayerNormalization(epsilon=1e-6)
            self.layernorm2 = LayerNormalization(epsilon=1e-6)
            self.dropout1 = Dropout(dropout_rate)
            self.dropout2 = Dropout(dropout_rate)
    
    def call(self, inputs, training):
        if not HAS_TF:
            return inputs
            
        attn_output = self.attention(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class TimeSeriesTransformer:
    """
    ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ìœ„í•œ Transformer ëª¨ë¸
    """
    
    def __init__(self, 
                 sequence_length: int = 60,
                 embed_dim: int = 64,
                 num_heads: int = 4,
                 ff_dim: int = 64,
                 num_transformer_blocks: int = 2,
                 dropout_rate: float = 0.1):
        
        self.sequence_length = sequence_length
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.ff_dim = ff_dim
        self.num_transformer_blocks = num_transformer_blocks
        self.dropout_rate = dropout_rate
        
        self.model = None
        self.scaler = MinMaxScaler()
        self.is_fitted = False
        
        if HAS_TF:
            self._build_model()
        else:
            logger.warning("TensorFlowê°€ ì—†ì–´ ê°„ë‹¨í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    def _build_model(self):
        """ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„±"""
        if not HAS_TF:
            return
            
        inputs = Input(shape=(self.sequence_length, 1))
        
        # Positional Encoding (ê°„ë‹¨í•œ ë²„ì „)
        x = Dense(self.embed_dim)(inputs)
        
        # Transformer ë¸”ë¡ë“¤
        for _ in range(self.num_transformer_blocks):
            x = TransformerBlock(self.embed_dim, self.num_heads, 
                               self.ff_dim, self.dropout_rate)(x)
        
        # Global Average Pooling
        x = GlobalAveragePooling1D()(x)
        
        # ìµœì¢… ì˜ˆì¸¡ ë ˆì´ì–´
        x = Dropout(self.dropout_rate)(x)
        x = Dense(32, activation="relu")(x)
        outputs = Dense(1)(x)  # ë‹¨ì¼ ê°’ ì˜ˆì¸¡
        
        self.model = Model(inputs, outputs)
        self.model.compile(optimizer=Adam(learning_rate=0.001), 
                          loss="mse", 
                          metrics=["mae"])
        
        logger.info(f"Transformer ëª¨ë¸ ìƒì„± ì™„ë£Œ: {self.model.count_params():,} íŒŒë¼ë¯¸í„°")
    
    def prepare_data(self, data: pd.Series) -> Tuple[np.ndarray, np.ndarray]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ë°ì´í„° ì •ê·œí™”
        scaled_data = self.scaler.fit_transform(data.values.reshape(-1, 1))
        
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i-self.sequence_length:i, 0])
            y.append(scaled_data[i, 0])
        
        return np.array(X), np.array(y)
    
    def fit(self, 
            price_data: pd.Series, 
            epochs: int = 50,
            batch_size: int = 32,
            validation_split: float = 0.2):
        """ëª¨ë¸ í•™ìŠµ"""
        
        if not HAS_TF or self.model is None:
            # ê°„ë‹¨í•œ ëŒ€ì²´ ëª¨ë¸ (ì´ë™í‰ê·  ê¸°ë°˜)
            self.simple_model_data = price_data.rolling(window=20).mean()
            self.is_fitted = True
            logger.info("ê°„ë‹¨í•œ ì´ë™í‰ê·  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            return
        
        try:
            # ë°ì´í„° ì¤€ë¹„
            X, y = self.prepare_data(price_data)
            X = X.reshape((X.shape[0], X.shape[1], 1))
            
            logger.info(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {X.shape}")
            
            # ëª¨ë¸ í•™ìŠµ
            history = self.model.fit(
                X, y,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=validation_split,
                verbose=1,
                callbacks=[
                    tf.keras.callbacks.EarlyStopping(
                        patience=10, restore_best_weights=True
                    )
                ]
            )
            
            self.is_fitted = True
            
            # í›ˆë ¨ ê²°ê³¼ ë¡œê·¸
            final_loss = history.history['loss'][-1]
            val_loss = history.history.get('val_loss', [0])[-1]
            logger.info(f"Transformer í•™ìŠµ ì™„ë£Œ - Loss: {final_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            return history
            
        except Exception as e:
            logger.error(f"Transformer ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            # ëŒ€ì²´ ëª¨ë¸ë¡œ ë˜ëŒë¦¬ê¸°
            self.simple_model_data = price_data.rolling(window=20).mean()
            self.is_fitted = True
    
    def predict_next_price(self, recent_prices: pd.Series) -> float:
        """ë‹¤ìŒ ê°€ê²© ì˜ˆì¸¡"""
        if not self.is_fitted:
            logger.warning("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return recent_prices.iloc[-1]  # ë§ˆì§€ë§‰ ê°€ê²© ë°˜í™˜
        
        if not HAS_TF or self.model is None:
            # ê°„ë‹¨í•œ ì˜ˆì¸¡ (ì´ë™í‰ê· )
            return recent_prices.rolling(window=min(20, len(recent_prices))).mean().iloc[-1]
        
        try:
            if len(recent_prices) < self.sequence_length:
                return recent_prices.iloc[-1]
            
            # ë§ˆì§€ë§‰ sequence_length ê°œ ë°ì´í„° ì‚¬ìš©
            last_sequence = recent_prices.tail(self.sequence_length)
            
            # ë°ì´í„° ì •ê·œí™”
            scaled_sequence = self.scaler.transform(last_sequence.values.reshape(-1, 1))
            
            # ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
            X = scaled_sequence.reshape(1, self.sequence_length, 1)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_scaled = self.model.predict(X, verbose=0)[0][0]
            
            # ì—­ì •ê·œí™”
            prediction = self.scaler.inverse_transform([[prediction_scaled]])[0][0]
            
            return prediction
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return recent_prices.iloc[-1]
    
    def predict_trend(self, recent_prices: pd.Series, horizon: int = 5) -> List[float]:
        """í–¥í›„ ì—¬ëŸ¬ ì‹œì ì˜ ê°€ê²© ì˜ˆì¸¡"""
        predictions = []
        current_prices = recent_prices.copy()
        
        for _ in range(horizon):
            next_price = self.predict_next_price(current_prices)
            predictions.append(next_price)
            
            # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì˜ˆì¸¡ê°’ì„ ì¶”ê°€
            new_index = len(current_prices)
            current_prices = pd.concat([
                current_prices, 
                pd.Series([next_price], index=[new_index])
            ])
        
        return predictions
    
    def get_prediction_confidence(self, recent_prices: pd.Series) -> Dict[str, float]:
        """ì˜ˆì¸¡ ì‹ ë£°ë„ ê³„ì‚°"""
        if not self.is_fitted:
            return {'confidence': 0.5, 'volatility': 0.02}
        
        # ìµœê·¼ ë³€ë™ì„± ê³„ì‚°
        returns = recent_prices.pct_change().dropna()
        volatility = returns.std()
        
        # ê°„ë‹¨í•œ ì‹ ë£°ë„ ì§€í‘œ
        # ë³€ë™ì„±ì´ ë‚®ì„ìˆ˜ë¡ ì‹ ë£°ë„ ë†’ìŒ
        confidence = max(0.3, 1.0 - volatility * 10)
        confidence = min(0.9, confidence)
        
        return {
            'confidence': confidence,
            'volatility': volatility,
            'trend_strength': abs(returns.mean() / (volatility + 1e-8))
        }
    
    def save_model(self, filepath: str):
        """ëª¨ë¸ ì €ì¥"""
        if self.model and HAS_TF:
            self.model.save(filepath)
            logger.info(f"Transformer ëª¨ë¸ ì €ì¥: {filepath}")
        else:
            import pickle
            with open(f"{filepath}.pkl", 'wb') as f:
                pickle.dump({
                    'simple_model_data': getattr(self, 'simple_model_data', None),
                    'scaler': self.scaler
                }, f)
            logger.info(f"ê°„ë‹¨í•œ ëª¨ë¸ ì €ì¥: {filepath}.pkl")
    
    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if HAS_TF:
                self.model = tf.keras.models.load_model(filepath)
                self.is_fitted = True
                logger.info(f"Transformer ëª¨ë¸ ë¡œë“œ: {filepath}")
            else:
                import pickle
                with open(f"{filepath}.pkl", 'rb') as f:
                    data = pickle.load(f)
                    self.simple_model_data = data['simple_model_data']
                    self.scaler = data['scaler']
                    self.is_fitted = True
                logger.info(f"ê°„ë‹¨í•œ ëª¨ë¸ ë¡œë“œ: {filepath}.pkl")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")

# ì „ì—­ ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤
transformer_predictor = TimeSeriesTransformer()

def get_transformer_predictor() -> TimeSeriesTransformer:
    """ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return transformer_predictor

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§  Transformer ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ì˜ˆì¸¡ê¸° ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    predictor = get_transformer_predictor()
    
    print("ğŸ“Š Transformer ëª¨ë¸ ì •ë³´:")
    print(f"  - ì‹œí€€ìŠ¤ ê¸¸ì´: {predictor.sequence_length}")
    print(f"  - ì„ë² ë”© ì°¨ì›: {predictor.embed_dim}")
    print(f"  - ì–´í…ì…˜ í—¤ë“œ: {predictor.num_heads}")
    print(f"  - í”¼ë“œí¬ì›Œë“œ ì°¨ì›: {predictor.ff_dim}")
    print(f"  - Transformer ë¸”ë¡ ìˆ˜: {predictor.num_transformer_blocks}")
    
    if HAS_TF:
        print(f"  - TensorFlow ë²„ì „: {tf.__version__}")
        print(f"  - ëª¨ë¸ íŒŒë¼ë¯¸í„°: {predictor.model.count_params():,}ê°œ")
    else:
        print("  - ê°„ë‹¨í•œ ì´ë™í‰ê·  ëª¨ë¸ ì‚¬ìš© ì¤‘")
    
    print("\nğŸ”® ê°€ìƒ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
    
    # ê°€ìƒ ì£¼ê°€ ë°ì´í„° ìƒì„± (ì‚¼ì„±ì „ì ìœ ì‚¬)
    np.random.seed(42)
    base_price = 70000
    days = 100
    
    # íŠ¸ë Œë“œ + ë…¸ì´ì¦ˆ
    trend = np.linspace(0, 10000, days)
    noise = np.random.normal(0, 2000, days)
    prices = base_price + trend + noise
    
    # ìŒìˆ˜ ë°©ì§€
    prices = np.maximum(prices, 50000)
    
    price_series = pd.Series(prices)
    print(f"  ğŸ“ˆ ê°€ìƒ ì£¼ê°€ ë°ì´í„°: {len(price_series)}ì¼")
    print(f"  ğŸ’° ì‹œì‘ê°€: {prices[0]:,.0f}ì›")
    print(f"  ğŸ’° ì¢…ë£Œê°€: {prices[-1]:,.0f}ì›")
    
    # ëª¨ë¸ í•™ìŠµ
    print("\nğŸ“ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    try:
        history = predictor.fit(price_series, epochs=10, batch_size=16)
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    print("\nğŸ”® ê°€ê²© ì˜ˆì¸¡:")
    try:
        # ë‹¨ì¼ ì˜ˆì¸¡
        next_price = predictor.predict_next_price(price_series.tail(60))
        print(f"  ğŸ¯ ë‹¤ìŒ ê°€ê²© ì˜ˆì¸¡: {next_price:,.0f}ì›")
        
        current_price = prices[-1]
        expected_return = (next_price - current_price) / current_price * 100
        print(f"  ğŸ“Š ì˜ˆìƒ ìˆ˜ìµë¥ : {expected_return:+.2f}%")
        
        # ë‹¤ì¤‘ ì˜ˆì¸¡ (5ì¼)
        future_prices = predictor.predict_trend(price_series.tail(60), horizon=5)
        print(f"\nğŸ“… í–¥í›„ 5ì¼ ì˜ˆì¸¡:")
        for i, price in enumerate(future_prices):
            day_return = (price - current_price) / current_price * 100
            print(f"    {i+1}ì¼ í›„: {price:,.0f}ì› ({day_return:+.2f}%)")
        
        # ì‹ ë£°ë„ ë¶„ì„
        confidence_info = predictor.get_prediction_confidence(price_series.tail(30))
        print(f"\nğŸ¯ ì˜ˆì¸¡ ì‹ ë£°ë„:")
        print(f"  - ì‹ ë£°ë„: {confidence_info['confidence']:.1%}")
        print(f"  - ë³€ë™ì„±: {confidence_info['volatility']:.3f}")
        print(f"  - íŠ¸ë Œë“œ ê°•ë„: {confidence_info.get('trend_strength', 0):.3f}")
        
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
    
    # ëª¨ë¸ ì €ì¥ í…ŒìŠ¤íŠ¸
    print("\nğŸ’¾ ëª¨ë¸ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸:")
    try:
        model_path = "models/test_transformer"
        predictor.save_model(model_path)
        print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        
        # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¡œë“œ í…ŒìŠ¤íŠ¸
        new_predictor = TimeSeriesTransformer()
        new_predictor.load_model(model_path)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ì˜ˆì¸¡ ë¹„êµ
        original_pred = predictor.predict_next_price(price_series.tail(60))
        loaded_pred = new_predictor.predict_next_price(price_series.tail(60))
        
        if abs(original_pred - loaded_pred) < 1:
            print("âœ… ëª¨ë¸ ì¼ê´€ì„± ê²€ì¦ í†µê³¼")
        else:
            print("âš ï¸ ëª¨ë¸ ì¼ê´€ì„± ì°¨ì´ ë°œìƒ")
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì €ì¥/ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    print("\nğŸ‰ Transformer ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ’¡ ì‹¤ì œ ê±°ë˜ì— ì‚¬ìš© ì‹œ:")
    print("  1. ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨")
    print("  2. ì •ê¸°ì ì¸ ëª¨ë¸ ì¬í›ˆë ¨")
    print("  3. ë‹¤ë¥¸ ì§€í‘œì™€ í•¨ê»˜ ì‹ ì¤‘í•œ í™œìš© ê¶Œì¥")

if __name__ == "__main__":
    main()
